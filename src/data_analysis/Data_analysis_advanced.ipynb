{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data analysis of Mutiny fault / error injection campaign </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# make plots interactable\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Load data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory where data is stored\n",
    "# base_dir = 'Q:/Marcello/thesis/paper/Prometheus_subset'\n",
    "base_dir = 'Q:/Mutiny'\n",
    "pattern = r'[0-9_]'\n",
    "\n",
    "# Function to load data from a file\n",
    "def load_metrics_data(file_path):\n",
    "    data = []\n",
    "    metric_name_base = os.path.basename(file_path).split('{')[0].replace(\"(\", \" \")\n",
    "    \n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            if 'OFFSET' in line:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Replace single quotes with double quotes only outside the JSON structure\n",
    "                safe_line = re.sub(r\"(?<!\\\\)'\", '\"', line)\n",
    "                \n",
    "                # Convert the JSON-like string to a Python dictionary\n",
    "                metric_data = json.loads(safe_line)\n",
    "                metric = metric_data['metric']\n",
    "                \n",
    "                if '__name__' not in metric:\n",
    "                    metric['__name__'] = metric_name_base\n",
    "                    \n",
    "                    if metric_name_base in [\"sum rate apiserver_request_total\", \"sum rate rest_client_requests_total\"]:\n",
    "                        metric['status_code'] = \"200\" if \"2\" in os.path.basename(file_path) else \"400/500\"\n",
    "                        \n",
    "                        # Extract job or kubernetes_pod_name based on metric name\n",
    "                        if metric_name_base == \"sum rate apiserver_request_total\":\n",
    "                            job_match = re.search(r\"job=_([^_]+)_\", os.path.basename(file_path))\n",
    "                            if job_match:\n",
    "                                metric['job'] = job_match.group(1)\n",
    "                        else:\n",
    "                            pod_match = re.search(r\"kubernetes_pod_name=_([^_]+)_\", os.path.basename(file_path))\n",
    "                            if pod_match:\n",
    "                                metric['kubernetes_pod_name'] = pod_match.group(1)\n",
    "                \n",
    "                data.append(metric_data)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "                \n",
    "    return data\n",
    "\n",
    "# Function to traverse directories and load data\n",
    "def load_all_data(base_dir):\n",
    "    all_data = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        condition_path = os.path.basename(os.path.dirname(os.path.dirname(root)))\n",
    "        is_baseline = condition_path == \"baselines\"\n",
    "        \n",
    "        if not is_baseline: # baseline's and other's metrics have different paths\n",
    "            condition_path = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(root))))\n",
    "        \n",
    "        workload_path = os.path.basename(os.path.dirname(root))\n",
    "        workload_name = re.sub(pattern, '', workload_path)\n",
    "\n",
    "        for file in files:\n",
    "            if 'DS_Store' in file: # MacOS useless files\n",
    "                continue\n",
    "            \n",
    "            file_path = os.path.join(root, file)\n",
    "            metric_data = load_metrics_data(file_path)\n",
    "            \n",
    "            for entry in metric_data:\n",
    "                entry['condition'] = condition_path if is_baseline else os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(root))))\n",
    "                entry['workload'] = workload_name\n",
    "                all_data.append(entry)\n",
    "                \n",
    "    return all_data\n",
    "\n",
    "# Load the data\n",
    "data = load_all_data(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data aggregation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier analysis\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Clean the data frame\n",
    "\n",
    "# Convert 'value' from string to float and extract timestap\n",
    "df['timestamp'] = df['value'].apply(lambda x: x[0])\n",
    "df['value'] = df['value'].apply(lambda x: float(x[1]))\n",
    "\n",
    "# Extract the metric's fields\n",
    "df['name'] = df['metric'].apply(lambda x: x.get('__name__'))\n",
    "df['endpoint'] = df['metric'].apply(lambda x: x.get('endpoint'))\n",
    "df['replicaset'] = df['metric'].apply(lambda x: x.get('replicaset').split('-')[0] if x and 'replicaset' in x else None)\n",
    "df['device'] = df['metric'].apply(lambda x: x.get('device'))\n",
    "df['instance'] = df['metric'].apply(lambda x: x.get('instance'))\n",
    "df['resource'] = df['metric'].apply(lambda x: x.get('resource'))\n",
    "df['job'] = df['metric'].apply(lambda x: x.get('job'))\n",
    "df['kubernetes_pod_name'] = df['metric'].apply(lambda x: x.get('kubernetes_pod_name'))\n",
    "\n",
    "df['container'] = df['metric'].apply(lambda x: x.get('container'))\n",
    "df['phase'] = df['metric'].apply(lambda x: x.get('phase'))\n",
    "\n",
    "# reasons metrics\n",
    "df['reason'] = df['metric'].apply(lambda x: x.get('reason'))\n",
    "\n",
    "df['uid'] = df['metric'].apply(lambda x: x.get('uid'))\n",
    "\n",
    "# histogram metrics\n",
    "df['le'] = df['metric'].apply(lambda x: float(x.get('le')) if x and 'le' in x else None)\n",
    "\n",
    "# status metrics\n",
    "df['status_code'] = df['metric'].apply(lambda x: x.get('status_code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields\n",
    "\n",
    "# aggregated_df_all = df.groupby(['name', 'condition', 'workload']).agg(\n",
    "#     mean_value=('value', 'mean')\n",
    "# ).reset_index()\n",
    "\n",
    "# list of available metrics\n",
    "fields_list = df.groupby(['name']).agg(\n",
    "    mean_value=('value', 'mean')\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Visualization </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "def plot_metric_boxplot(df, metric_name, title=\"Missing title\", y_label=None, value_to_show=\"value\"):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    \n",
    "    for i, workload in enumerate([\"availab\", \"deploy\", \"scale\"]):\n",
    "    \n",
    "        # Filter the DataFrame for the specific metric\n",
    "        filtered_df = df[df['name'] == metric_name]\n",
    "        filtered_df = filtered_df[filtered_df['workload'] == workload]\n",
    "                \n",
    "        # Create a boxplot grouped by condition\n",
    "        sns.boxplot(x='condition', y=value_to_show, data=filtered_df, hue='condition', showmeans=True, ax=axes[i])\n",
    "        \n",
    "        axes[i].set_title(f'{workload}')\n",
    "        axes[i].set_xlabel('')\n",
    "        axes[i].set_ylabel(' ')\n",
    "    \n",
    "    # Set shared labels\n",
    "    fig.supylabel(y_label if y_label else \"Value\")\n",
    "    fig.supxlabel('Condition')\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    fig.set_label(\" \")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violinplot\n",
    "def plot_metric_violinplot(df, metric_name, title=\"Missing title\", y_label=None, value_to_show=\"value\"):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    \n",
    "    for i, workload in enumerate([\"availab\", \"deploy\", \"scale\"]):\n",
    "    \n",
    "        # Filter the DataFrame for the specific metric\n",
    "        filtered_df = df[df['name'] == metric_name]\n",
    "        filtered_df = filtered_df[filtered_df['workload'] == workload]\n",
    "                \n",
    "        # Create a boxplot grouped by condition\n",
    "        sns.violinplot(x='condition', y=value_to_show, data=filtered_df, hue='condition', ax=axes[i])\n",
    "        \n",
    "        axes[i].set_title(f'{workload}')\n",
    "        axes[i].set_xlabel('')\n",
    "        axes[i].set_ylabel(' ')\n",
    "    \n",
    "    # Set shared labels\n",
    "    fig.supylabel(y_label if y_label else \"Value\")\n",
    "    fig.supxlabel('Condition')\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    fig.set_label(\" \")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "def plot_metric_heatmap(df, metric_name, title=\"Missing title\", y_label=None, value_to_show=\"value\", split_by=None, show_numbers=False):\n",
    "    \n",
    "    # Filter the DataFrame for the specific metric\n",
    "    filtered_df = df[df['name'] == metric_name]\n",
    "\n",
    "    # Create a composite index for rows combining condition and split_by values if provided\n",
    "    if split_by:\n",
    "        filtered_df['composite_index'] = filtered_df['condition'].astype(str)\n",
    "        for col in split_by:\n",
    "            filtered_df['composite_index'] += \"-\" + filtered_df[col].astype(str)\n",
    "        index_column = 'composite_index'\n",
    "    else:\n",
    "        index_column = 'condition'\n",
    "\n",
    "    # Pivot the data to create a matrix suitable for heatmap\n",
    "    heatmap_data = filtered_df.pivot_table(index=index_column, columns='workload', values=value_to_show, aggfunc='mean')\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    \n",
    "    if show_numbers:\n",
    "        sns.heatmap(heatmap_data, fmt=\".2f\", cmap=sns.cubehelix_palette(as_cmap=True), cbar_kws={'label': y_label or \"Value\"}, annot=True)\n",
    "    \n",
    "    else:\n",
    "        ax = sns.heatmap(heatmap_data, fmt=\".2f\", cmap=sns.cubehelix_palette(as_cmap=True), cbar_kws={'label': y_label or \"Value\"}) \n",
    "        \n",
    "        colorbar = ax.collections[0].colorbar\n",
    "        min_val, max_val = heatmap_data.min().min(), heatmap_data.max().max()  # Ottieni il minimo e il massimo dai dati\n",
    "        colorbar.set_ticks([min_val, (min_val + max_val) / 2, max_val])\n",
    "        colorbar.set_ticklabels(['low', 'med', 'high'])\n",
    "    \n",
    "    # Set labels and title\n",
    "    plt.xlabel('workload')\n",
    "    plt.ylabel('Condition' if not split_by else 'Condition & Split By')\n",
    "    plt.title(title, fontsize=16)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print plotbox metrics\n",
    "def print_metrics(metric_names, split_by, to_skip, y_label=None, value_to_show=\"value\", plot_violin=False):\n",
    "    # Filter DataFrame\n",
    "    df_filtered_by_name = df[df['name'].isin(metric_names)]\n",
    "\n",
    "    # Ensure split_by is a list\n",
    "    if isinstance(split_by, str):\n",
    "        split_by = [split_by]\n",
    "\n",
    "    # Add the 'name' column to split_by for grouping\n",
    "    group_by_columns = ['name'] + split_by + ['condition', 'workload']\n",
    "\n",
    "    if value_to_show != \"value\":\n",
    "        aggregated_df_splitted = df_filtered_by_name.groupby(group_by_columns).agg(\n",
    "            mean_value=('value', 'mean'),\n",
    "            sum_value=('value', 'sum')\n",
    "        ).reset_index().sort_values(\"condition\")\n",
    "        \n",
    "    else:\n",
    "        aggregated_df_splitted = df_filtered_by_name.groupby(group_by_columns + ['value']).agg(\n",
    "            mean_value=('value', 'mean'),\n",
    "        ).reset_index().sort_values(\"condition\")\n",
    "\n",
    "    # Filter out entries to be skipped\n",
    "    for metric in metric_names:\n",
    "        # Generate a unique combination of split_by values\n",
    "        for combination in aggregated_df_splitted[split_by].drop_duplicates().itertuples(index=False):\n",
    "            # Skip if any of the split_by values in the combination should be skipped\n",
    "            if any(el in to_skip for el in combination):\n",
    "                continue\n",
    "            \n",
    "            # Filter the DataFrame for the current combination\n",
    "            condition = (aggregated_df_splitted[split_by[0]] == combination[0])\n",
    "            \n",
    "            for i, col in enumerate(split_by[1:], start=1):\n",
    "                condition &= (aggregated_df_splitted[col] == combination[i])\n",
    "                \n",
    "            aggregated_df_filtered = aggregated_df_splitted[condition]\n",
    "            \n",
    "            # Generate a label for the plot\n",
    "            label = \" - \".join([f\"{col}={value}\" for col, value in zip(split_by, combination)])\n",
    "            plot_metric_boxplot(aggregated_df_filtered, metric, f\"{metric} - {label}\", y_label, value_to_show)\n",
    "            \n",
    "            if plot_violin:\n",
    "                plot_metric_violinplot(aggregated_df_filtered, metric, f\"{metric} - {label}\", y_label, value_to_show)\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print heatmap metrics\n",
    "def print_metrics_heatmap(metric_names, split_by, to_skip, y_label=None, value_to_show=\"value\", show_numbers=False):\n",
    "    # Filter DataFrame\n",
    "    df_filtered_by_name = df[df['name'].isin(metric_names)]\n",
    "\n",
    "    # Ensure split_by is a list\n",
    "    if isinstance(split_by, str):\n",
    "        split_by = [split_by]\n",
    "\n",
    "    # Add the 'name' column to split_by for grouping\n",
    "    group_by_columns = ['name'] + split_by + ['condition', 'workload']\n",
    "\n",
    "    if value_to_show != \"value\":\n",
    "        aggregated_df_splitted = df_filtered_by_name.groupby(group_by_columns).agg(\n",
    "            mean_value=('value', 'mean'),\n",
    "            sum_value=('value', 'sum')\n",
    "        ).reset_index().sort_values(\"condition\")\n",
    "        \n",
    "    else:\n",
    "        aggregated_df_splitted = df_filtered_by_name.groupby(group_by_columns + ['value']).agg(\n",
    "            mean_value=('value', 'mean'),\n",
    "        ).reset_index().sort_values(\"condition\")\n",
    "\n",
    "    # Filter out entries to be skipped\n",
    "    for metric in metric_names:\n",
    "        # Generate a unique combination of split_by values\n",
    "        for combination in aggregated_df_splitted[split_by].drop_duplicates().itertuples(index=False):\n",
    "            # Skip if any of the split_by values in the combination should be skipped\n",
    "            if any(el in to_skip for el in combination):\n",
    "                continue\n",
    "            \n",
    "            # Filter the DataFrame for the current combination\n",
    "            condition = (aggregated_df_splitted[split_by[0]] == combination[0])\n",
    "            \n",
    "            for i, col in enumerate(split_by[1:], start=1):\n",
    "                condition &= (aggregated_df_splitted[col] == combination[i])\n",
    "                \n",
    "            aggregated_df_filtered = aggregated_df_splitted[condition]\n",
    "            \n",
    "            # Generate a label for the plot\n",
    "            label = \" - \".join([f\"{col}={value}\" for col, value in zip(split_by, combination)])\n",
    "            plot_metric_heatmap(aggregated_df_filtered, metric, f\"{metric} - {label}\", y_label, value_to_show, show_numbers=show_numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Boxplots</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Kube_endpoint</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = ['kube_endpoint_address_available', 'kube_endpoint_address_not_ready']\n",
    "metric_names = ['kube_endpoint_address_available']\n",
    "split_by='endpoint'\n",
    "\n",
    "wrong_endpoints = [\"kbench-service-oid-0-tid-0\", \"kcench-service-oid-0-tid-0\", \"jbench-service-oid-0-tid-0\", \"nnde-exporter\"]\n",
    "endpoints_to_skip = [\"prometheus-service\", \"kubernetes\", \"kube-state-metrics\"] + wrong_endpoints\n",
    "\n",
    "print_metrics(metric_names, split_by, endpoints_to_skip, y_label=\"Count\")\n",
    "# print_metrics_heatmap(metric_names, split_by, endpoints_to_skip, y_label=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean endpoints vars\n",
    "del wrong_endpoints\n",
    "del endpoints_to_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Replica sets</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names = ['kube_replicaset_status_ready_replicas', 'kube_replicaset_status_replicas',]\n",
    "\n",
    "split_by = 'replicaset'\n",
    "\n",
    "wrong_rs = [\"kbench\", \"kcench\", \"jbench\", \"nnde-exporter\"]\n",
    "rs_to_skip = [\"prometheus-service\", \"kubernetes\", \"kube-state-metrics\"] + wrong_rs\n",
    "\n",
    "print_metrics(metric_names, split_by, rs_to_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean replcia set vars\n",
    "del wrong_rs\n",
    "del rs_to_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Node file system bytes</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = ['min node_filesystem_avail_bytes', 'min node_filesystem_free_bytes',]\n",
    "metric_names = ['min node_filesystem_free_bytes',]\n",
    "split_by = 'device'\n",
    "device_to_skip = [\"tmpfs\", \"shm\",] \n",
    "\n",
    "print_metrics(metric_names, split_by, device_to_skip, plot_violin=False)\n",
    "print_metrics_heatmap(metric_names, split_by, device_to_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean node file system bytes\n",
    "del device_to_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>node_filefd_allocated</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names = ['node_filefd_allocated',]\n",
    "\n",
    "split_by = 'instance'\n",
    "\n",
    "print_metrics(metric_names, split_by, [])\n",
    "# print_metrics_heatmap(metric_names, split_by, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>node_load5<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names = ['node_load5',]\n",
    "\n",
    "split_by = 'instance'\n",
    "\n",
    "print_metrics(metric_names, split_by, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Node memory</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"node_memory_Buffers_bytes\", \"node_memory_Cached_bytes\", \"node_memory_MemFree_bytes\", \"node_memory_Shmem_bytes\", \"node_memory_Slab_bytes\", \"node_memory_VmallocUsed_bytes\"]\n",
    "metric_names = [\"node_memory_Cached_bytes\"]\n",
    "\n",
    "split_by = 'instance'\n",
    "to_skip = [\"192.168.100.2:9100\", \"192.168.100.3:9100\", \"192.168.100.4:9100\"]\n",
    "\n",
    "print_metrics(metric_names, split_by, to_skip)\n",
    "print_metrics_heatmap(metric_names, split_by, to_skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Node network stats</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"node_netstat_Tcp_CurrEstab\", \"node_procs_blocked\", \"node_sockstat_TCP_inuse\", \"node_sockstat_TCP_mem\",]\n",
    "metric_names = [\"node_sockstat_TCP_mem\"]\n",
    "\n",
    "split_by = 'instance'\n",
    "\n",
    "print_metrics(metric_names, split_by, [])\n",
    "# print_metrics(metric_names, split_by, [], value_to_show=\"sum_value\")\n",
    "# print_metrics_heatmap(metric_names, split_by, [], value_to_show=\"sum_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Rates</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"rate node_context_switches_total\", \"rate process_cpu_seconds_total\", \"rate process_resident_memory_bytes\"]\n",
    "metric_names = [\"rate process_resident_memory_bytes\"]\n",
    "\n",
    "split_by = 'instance'\n",
    "\n",
    "print_metrics(metric_names, split_by, [])\n",
    "# print_metrics_heatmap(metric_names, split_by, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Node status capacity</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names = [\"sum kube_node_status_capacity_offset_offset_time)_by_ resource)\"]\n",
    "\n",
    "split_by = 'resource'\n",
    "to_skip = [\"cpu\", \"hugepages_2Mi\", \"pods\", \"ephemeral_storage\"]\n",
    "\n",
    "print_metrics(metric_names, split_by, to_skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Rate node network stats</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"sum rate node_netstat_Tcp_InErrs\", \"sum rate node_netstat_Tcp_RetransSegs\", \"sum rate node_network_carrier_changes_total\", \"sum rate node_network_receive_packets_total\", \"sum rate node_network_transmit_packets_total\"]\n",
    "metric_names = [\"sum rate node_network_transmit_packets_total\"]\n",
    "\n",
    "split_by = 'instance'\n",
    "\n",
    "print_metrics(metric_names, split_by, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Node work queue</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"sum rate workqueue_adds_total\", \"sum rate workqueue_depth\"]\n",
    "metric_names = [\"sum rate workqueue_depth\"]\n",
    "\n",
    "split_by = 'job'\n",
    "\n",
    "# Filter DataFrame\n",
    "df_filtered_by_name = df[df['name'].isin(metric_names)]\n",
    "\n",
    "aggregated_df_splitted = df_filtered_by_name.groupby(['name', 'condition', 'workload', 'value']).agg(\n",
    "    mean_value=('value', 'mean')\n",
    ").reset_index().sort_values(\"condition\")\n",
    "# kube_endpoint_address_not_ready - useless\n",
    "for metric in metric_names:\n",
    "    plot_metric_boxplot(aggregated_df_splitted, metric, f\"{metric} - \")\n",
    "    # plot_metric_heatmap(aggregated_df_splitted, metric, f\"{metric} - \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Status code</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"sum rate apiserver_request_total\", \"sum rate rest_client_requests_total\"]\n",
    "metric_names = [\"sum rate apiserver_request_total\"]\n",
    "\n",
    "split_by = 'status_code'\n",
    "# split_by = 'job'\n",
    "\n",
    "print_metrics(metric_names_full, split_by, [])\n",
    "# print_metrics_heatmap(metric_names_full, split_by, [], show_numbers=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Changes</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"changes kube_pod_container_status_restarts_total[10s]_offset_offset_time)___0\", \"changes kube_pod_status_phase[10s]_offset_offset_time)_!=_0\"]\n",
    "metric_names = [\"changes kube_pod_container_status_restarts_total[10s]_offset_offset_time)___0\"]\n",
    "\n",
    "split_by = 'container'\n",
    "to_skip = [\"iello-dep\", \"hdllo-dep\", \"kube-proxy\"]\n",
    "# print_metrics(metric_names, split_by, to_skip, value_to_show=\"sum_value\")\n",
    "print_metrics_heatmap(metric_names, split_by, to_skip, value_to_show=\"sum_value\", show_numbers=True)\n",
    "\n",
    "# split_by = 'phase'\n",
    "# to_skip = [\"Succeeded\"]\n",
    "# # print_metrics(metric_names, split_by, to_skip, y_label=\"Sum\", value_to_show=\"sum_value\")\n",
    "# print_metrics_heatmap(metric_names, split_by, to_skip, value_to_show=\"sum_value\", show_numbers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Reason</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"kube_pod_container_status_terminated_reason\", \"kube_pod_container_status_waiting_reason\"]\n",
    "metric_names = [\"kube_pod_container_status_terminated_reason\"]\n",
    "\n",
    "split_by = [\"reason\", \"container\"]\n",
    "to_skip = [\"iello-dep\", \"hdllo-dep\", \"kube-proxy\", \"completed\", \"kube-flannel\", \"ContainerStatusUnknown\"]\n",
    "\n",
    "# print_metrics(metric_names, split_by, to_skip, y_label=\"Sum\", value_to_show=\"sum_value\")\n",
    "print_metrics_heatmap(metric_names, split_by, to_skip, y_label=\"Sum\", value_to_show=\"sum_value\", show_numbers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Histograms</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "metric_names = [\"sum rate apiserver_request_duration_seconds_bucket\", \"sum rate rest_client_request_duration_seconds_bucket[10s]_offset_offset_time))_by_ le)\", \"sum rate workqueue_queue_duration_seconds_bucket\"]\n",
    "\n",
    "df_filtered_by_name = df[df['name'].isin(metric_names)]\n",
    "df_grouped = df_filtered_by_name.groupby(['name', 'le', 'condition', 'workload']).agg(\n",
    "        mean_value=('value', 'mean')\n",
    ").reset_index().sort_values(\"le\").sort_values(\"condition\")\n",
    "\n",
    "for metric_name in metric_names:\n",
    "\n",
    "        # Create subplots: 1 row and 3 columns (for the three workloads)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "        # Iterate through each workload and corresponding subplot axis\n",
    "        for i, workload in enumerate([\"availab\", \"deploy\", \"scale\"]):\n",
    "                # Filter the DataFrame for the specific workload and create a copy\n",
    "                filtered_df = df_grouped[df_grouped['workload'] == workload].copy()\n",
    "                filtered_df = filtered_df[filtered_df['name'] == metric_name].copy()\n",
    "\n",
    "                # Replace +Inf with a large finite value using .loc[]\n",
    "                filtered_df.loc[filtered_df['le'] == float('inf'), 'le'] = 65\n",
    "\n",
    "                # Filter by le value if necessary\n",
    "                # filtered_df = filtered_df[filtered_df['le'] < 61]\n",
    "\n",
    "                # Plotting the occurrence (frequency) histogram for all conditions in the same subplot\n",
    "                ax = sns.histplot(x='le', y='mean_value', data=filtered_df, bins=30, hue='condition', palette=\"husl\", ax=axes[i])\n",
    "                axes[i].set_title(f'workload: {workload}')\n",
    "                axes[i].set_xlabel('')\n",
    "                axes[i].set_ylabel(' ')\n",
    "                ticks = np.concatenate((np.arange(0, 10, step=2), np.arange(10, 61, step=10), np.arange(65, 66, step=1)))\n",
    "\n",
    "                ax.set_xticks(ticks)\n",
    "                # axes[i].xticks(ticks)\n",
    "                sns.move_legend(ax, \"lower right\")\n",
    "\n",
    "        # Set the shared y-label\n",
    "        fig.supylabel('Mean rate value (request per second)')\n",
    "        fig.supxlabel('le (request solved under x second)')\n",
    "        fig.suptitle(metric_name, fontsize=16)\n",
    "        fig.set_label(\" \")\n",
    "        # Adjust the layout for better spacing\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear histogram's vars\n",
    "del ticks\n",
    "del ax\n",
    "del fig\n",
    "del axes\n",
    "del df_grouped\n",
    "del df_filtered_by_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Times</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the time from when a\n",
    "def print_time_metrics(metric_names_to_differ):\n",
    "    # Filter DataFrame by metric names\n",
    "    df_filtered = df[df['name'].isin(metric_names_to_differ)]\n",
    "\n",
    "    # Define the necessary grouping columns\n",
    "    group_by_columns = ['name', 'condition', 'workload', 'uid']\n",
    "    group_by_columns2 = ['condition', 'workload', 'uid']\n",
    "\n",
    "    # Aggregate data\n",
    "    aggregated_df = df_filtered.groupby(group_by_columns).agg(\n",
    "        mean_value=('value', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    aggregated_df_splitted = aggregated_df.groupby(group_by_columns2).agg(\n",
    "        diff_value=('mean_value', lambda x: x.max() - x.min())\n",
    "    ).reset_index()\n",
    "\n",
    "    # Set up subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "    # Plot each workload in separate subplots\n",
    "    for i, workload in enumerate([\"availab\", \"deploy\", \"scale\"]):\n",
    "        filtered_df = aggregated_df_splitted[aggregated_df_splitted['workload'] == workload]\n",
    "        \n",
    "        # Create a boxplot\n",
    "        sns.boxplot(x='condition', y='diff_value', data=filtered_df, hue='condition', ax=axes[i])\n",
    "        \n",
    "        axes[i].set_title(workload)\n",
    "        axes[i].set_xlabel('')\n",
    "        axes[i].set_ylabel(\"Value [s]\")\n",
    "\n",
    "    # Set shared labels and title\n",
    "    fig.supxlabel('Condition')\n",
    "    fig.suptitle(f\"{metric_names_to_differ[1]} - {metric_names_to_differ[0]}\", fontsize=16)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define desired metric names\n",
    "metric_names_full = [\"kube_pod_container_state_started\", \"kube_pod_status_scheduled_time\", \"kube_pod_created\", \"kube_pod_start_time\"]\n",
    "metric_names = [\"kube_pod_status_scheduled_time\", \"kube_pod_created\"]\n",
    "metric_names2 = [\"kube_pod_status_scheduled_time\", \"kube_pod_container_state_started\"]\n",
    "metric_names3 = [\"kube_pod_created\", \"kube_pod_container_state_started\"]\n",
    "\n",
    "print_time_metrics(metric_names)\n",
    "print_time_metrics(metric_names2)\n",
    "print_time_metrics(metric_names3)\n",
    "\n",
    "# Check if exists data with a time difference\n",
    "# inconsistent_data = df[(df['name'] == 'kube_pod_created') | (df['name'] == 'kube_pod_container_state_started')] \\\n",
    "#     .groupby('uid') \\\n",
    "#     .filter(lambda group: len(group['value'].unique()) > 1)\n",
    "\n",
    "# print(inconsistent_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> ALL FIELDS </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(field_group)\n",
    "print_all = False\n",
    "\n",
    "if print_all:\n",
    "    for label, content in field_group.items():\n",
    "        for metric in content:\n",
    "            if not metric.isnumeric():\n",
    "            \n",
    "                print(f\"\\n{metric}\")\n",
    "                try:\n",
    "                    # plot_metric_violin(df, metric)\n",
    "                    plot_metric_boxplot(df, metric)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
