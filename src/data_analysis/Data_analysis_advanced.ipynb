{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data analysis of Mutiny fault / error injection campaign </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# make plots interactable\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Load data </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base directory where data is stored\n",
    "# base_dir = 'Q:/Marcello/thesis/paper/Prometheus_subset'\n",
    "base_dir = 'Q:/Mutiny'\n",
    "pattern = r'[0-9_]'\n",
    "\n",
    "# Function to load data from a file\n",
    "def load_metrics_data(file_path):\n",
    "    data = []\n",
    "    metric_name_base = os.path.basename(file_path).split('{')[0].replace(\"(\", \" \")\n",
    "    \n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            if 'OFFSET' in line:\n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                # Replace single quotes with double quotes only outside the JSON structure\n",
    "                safe_line = re.sub(r\"(?<!\\\\)'\", '\"', line)\n",
    "                \n",
    "                # Convert the JSON-like string to a Python dictionary\n",
    "                metric_data = json.loads(safe_line)\n",
    "                metric = metric_data['metric']\n",
    "                \n",
    "                if '__name__' not in metric:\n",
    "                    metric['__name__'] = metric_name_base\n",
    "                    \n",
    "                    if metric_name_base in [\"sum rate apiserver_request_total\", \"sum rate rest_client_requests_total\"]:\n",
    "                        metric['status_code'] = \"200\" if \"2\" in os.path.basename(file_path) else \"400/500\"\n",
    "                        \n",
    "                        # Extract job or kubernetes_pod_name based on metric name\n",
    "                        if metric_name_base == \"sum rate apiserver_request_total\":\n",
    "                            job_match = re.search(r\"job=_([^_]+)_\", os.path.basename(file_path))\n",
    "                            if job_match:\n",
    "                                metric['job'] = job_match.group(1)\n",
    "                        else:\n",
    "                            pod_match = re.search(r\"kubernetes_pod_name=_([^_]+)_\", os.path.basename(file_path))\n",
    "                            if pod_match:\n",
    "                                metric['kubernetes_pod_name'] = pod_match.group(1)\n",
    "                \n",
    "                data.append(metric_data)\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "                \n",
    "    return data\n",
    "\n",
    "# Function to traverse directories and load data\n",
    "def load_all_data(base_dir):\n",
    "    all_data = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(base_dir):\n",
    "        condition_path = os.path.basename(os.path.dirname(os.path.dirname(root))).capitalize()\n",
    "        is_baseline = condition_path == \"Baselines\"\n",
    "        \n",
    "        if not is_baseline: # baseline's and other's metrics have different paths\n",
    "            condition_path = os.path.basename(os.path.dirname(os.path.dirname(os.path.dirname(root))))\n",
    "            \n",
    "            if condition_path == \"less_resources\":\n",
    "                condition_path = \"LeR\"\n",
    "            elif condition_path == \"more_resources\":\n",
    "                condition_path = \"MoR\"\n",
    "            elif condition_path == \"network\":\n",
    "                condition_path = \"Net\"\n",
    "        \n",
    "        workload_path = os.path.basename(os.path.dirname(root))\n",
    "        workload_name = re.sub(pattern, '', workload_path)\n",
    "\n",
    "        for file in files:\n",
    "            if 'DS_Store' in file: # MacOS useless files\n",
    "                continue\n",
    "            \n",
    "            file_path = os.path.join(root, file)\n",
    "            metric_data = load_metrics_data(file_path)\n",
    "            \n",
    "            for entry in metric_data:\n",
    "                entry['condition'] = condition_path\n",
    "                entry['workload'] = workload_name\n",
    "                all_data.append(entry)\n",
    "                \n",
    "    return all_data\n",
    "\n",
    "# Load the data\n",
    "data = load_all_data(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Data aggregation </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for easier analysis\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Clean the data frame\n",
    "\n",
    "# Convert 'value' from string to float and extract timestap\n",
    "df['timestamp'] = df['value'].apply(lambda x: x[0])\n",
    "df['value'] = df['value'].apply(lambda x: float(x[1]))\n",
    "\n",
    "# Extract the metric's fields\n",
    "df['name'] = df['metric'].apply(lambda x: x.get('__name__'))\n",
    "df['endpoint'] = df['metric'].apply(lambda x: x.get('endpoint'))\n",
    "df['replicaset'] = df['metric'].apply(lambda x: x.get('replicaset').split('-')[0] if x and 'replicaset' in x else None)\n",
    "df['device'] = df['metric'].apply(lambda x: x.get('device'))\n",
    "df['instance'] = df['metric'].apply(lambda x: x.get('instance'))\n",
    "df['resource'] = df['metric'].apply(lambda x: x.get('resource'))\n",
    "df['job'] = df['metric'].apply(lambda x: x.get('job'))\n",
    "df['kubernetes_pod_name'] = df['metric'].apply(lambda x: x.get('kubernetes_pod_name'))\n",
    "\n",
    "df['container'] = df['metric'].apply(lambda x: x.get('container'))\n",
    "df['phase'] = df['metric'].apply(lambda x: x.get('phase'))\n",
    "\n",
    "# reasons metrics\n",
    "df['reason'] = df['metric'].apply(lambda x: x.get('reason'))\n",
    "\n",
    "df['uid'] = df['metric'].apply(lambda x: x.get('uid'))\n",
    "\n",
    "# histogram metrics\n",
    "df['le'] = df['metric'].apply(lambda x: float(x.get('le')) if x and 'le' in x else None)\n",
    "\n",
    "# status metrics\n",
    "df['status_code'] = df['metric'].apply(lambda x: x.get('status_code'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fields\n",
    "\n",
    "# aggregated_df_all = df.groupby(['name', 'condition', 'workload']).agg(\n",
    "#     mean_value=('value', 'mean')\n",
    "# ).reset_index()\n",
    "\n",
    "# list of available metrics\n",
    "fields_list = df.groupby(['name']).agg(\n",
    "    mean_value=('value', 'mean')\n",
    ").reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Visualization </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot\n",
    "def plot_metric_boxplot(df, metric_name, title=\"Missing title\", y_label=None, value_to_show=\"value\"):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    \n",
    "    for i, workload in enumerate([\"availab\", \"deploy\", \"scale\"]):\n",
    "    \n",
    "        # Filter the DataFrame for the specific metric\n",
    "        filtered_df = df[df['name'] == metric_name]\n",
    "        filtered_df = filtered_df[filtered_df['workload'] == workload]\n",
    "                \n",
    "        # Create a boxplot grouped by condition\n",
    "        sns.set_theme(context=\"notebook\", style=\"white\", font_scale=2, palette=\"tab10\")\n",
    "        sns.boxplot(x='condition', y=value_to_show, data=filtered_df, hue='condition', showmeans=True, ax=axes[i])\n",
    "        \n",
    "        axes[i].set_title(f'{workload}')\n",
    "        axes[i].set_xlabel('')\n",
    "        axes[i].set_ylabel(' ')\n",
    "    \n",
    "    # Set shared labels\n",
    "    fig.supylabel(y_label if y_label else \"Value\", x=0.038)\n",
    "    fig.supxlabel('Condition', y=0.075)\n",
    "    fig.suptitle(title, y=0.95)\n",
    "    fig.set_label(\" \")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violinplot\n",
    "def plot_metric_violinplot(df, metric_name, title=\"Missing title\", y_label=None, value_to_show=\"value\"):\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "    \n",
    "    for i, workload in enumerate([\"availab\", \"deploy\", \"scale\"]):\n",
    "    \n",
    "        # Filter the DataFrame for the specific metric\n",
    "        filtered_df = df[df['name'] == metric_name]\n",
    "        filtered_df = filtered_df[filtered_df['workload'] == workload]\n",
    "                \n",
    "        # Create a boxplot grouped by condition\n",
    "        sns.violinplot(x='condition', y=value_to_show, data=filtered_df, hue='condition', ax=axes[i])\n",
    "        \n",
    "        axes[i].set_title(f'{workload}')\n",
    "        axes[i].set_xlabel('')\n",
    "        axes[i].set_ylabel(' ')\n",
    "    \n",
    "    # Set shared labels\n",
    "    fig.supylabel(y_label if y_label else \"Value\")\n",
    "    fig.supxlabel('Condition')\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    fig.set_label(\" \")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap\n",
    "def plot_metric_heatmap(df, metric_name, title=\"Missing title\", y_label=None, value_to_show=\"value\", split_by=None, show_numbers=False):\n",
    "    \n",
    "    # Filter the DataFrame for the specific metric\n",
    "    filtered_df = df[df['name'] == metric_name]\n",
    "\n",
    "    # Create a composite index for rows combining condition and split_by values if provided\n",
    "    if split_by:\n",
    "        filtered_df['composite_index'] = filtered_df['condition'].astype(str)\n",
    "        for col in split_by:\n",
    "            filtered_df['composite_index'] += \"-\" + filtered_df[col].astype(str)\n",
    "        index_column = 'composite_index'\n",
    "    else:\n",
    "        index_column = 'condition'\n",
    "\n",
    "\n",
    "    sns.set_theme(context=\"notebook\", style=\"white\", font_scale=1.5, palette=\"tab10\")\n",
    "\n",
    "    # Pivot the data to create a matrix suitable for heatmap\n",
    "    heatmap_data = filtered_df.pivot_table(index=index_column, columns='workload', values=value_to_show, aggfunc='mean')\n",
    "\n",
    "    # Plot the heatmap\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    \n",
    "    if show_numbers:\n",
    "        sns.heatmap(heatmap_data, fmt=\".2f\", cmap=sns.cubehelix_palette(as_cmap=True), cbar_kws={'label': y_label or \"Value\"}, annot=True, annot_kws={\"fontsize\": 12})\n",
    "    \n",
    "    else:\n",
    "        ax = sns.heatmap(heatmap_data, fmt=\".2f\", cmap=sns.cubehelix_palette(as_cmap=True), cbar_kws={'label': y_label or \"Value\"}) \n",
    "        \n",
    "        colorbar = ax.collections[0].colorbar\n",
    "        min_val, max_val = heatmap_data.min().min(), heatmap_data.max().max()  # Ottieni il minimo e il massimo dai dati\n",
    "        colorbar.set_ticks([min_val, (min_val + max_val) / 2, max_val])\n",
    "        colorbar.set_ticklabels(['low', 'med', 'high'])\n",
    "    \n",
    "    plt.tick_params(axis='y', rotation=0)\n",
    "    # Set labels and title\n",
    "    plt.xlabel('workload')\n",
    "    plt.ylabel('Condition' if not split_by else 'Condition & Split By')\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print plotbox metrics\n",
    "def print_metrics(metric_names, split_by, to_skip, title=None, y_label=None, value_to_show=\"value\", plot_violin=False, show_split_by=True):\n",
    "    # Filter DataFrame\n",
    "    df_filtered_by_name = df[df['name'].isin(metric_names)]\n",
    "\n",
    "    # Ensure split_by is a list\n",
    "    if isinstance(split_by, str):\n",
    "        split_by = [split_by]\n",
    "\n",
    "    # Add the 'name' column to split_by for grouping\n",
    "    group_by_columns = ['name'] + split_by + ['condition', 'workload']\n",
    "\n",
    "    if value_to_show != \"value\":\n",
    "        aggregated_df_splitted = df_filtered_by_name.groupby(group_by_columns).agg(\n",
    "            mean_value=('value', 'mean'),\n",
    "            sum_value=('value', 'sum')\n",
    "        ).reset_index().sort_values(\"condition\")\n",
    "        \n",
    "    else:\n",
    "        aggregated_df_splitted = df_filtered_by_name.groupby(group_by_columns + ['value']).agg(\n",
    "            mean_value=('value', 'mean'),\n",
    "        ).reset_index().sort_values(\"condition\")\n",
    "\n",
    "    # Filter out entries to be skipped\n",
    "    for metric in metric_names:\n",
    "        # Generate a unique combination of split_by values\n",
    "        for combination in aggregated_df_splitted[split_by].drop_duplicates().itertuples(index=False):\n",
    "            # Skip if any of the split_by values in the combination should be skipped\n",
    "            if any(el in to_skip for el in combination):\n",
    "                continue\n",
    "            \n",
    "            # Filter the DataFrame for the current combination\n",
    "            condition = (aggregated_df_splitted[split_by[0]] == combination[0])\n",
    "            \n",
    "            for i, col in enumerate(split_by[1:], start=1):\n",
    "                condition &= (aggregated_df_splitted[col] == combination[i])\n",
    "                \n",
    "            aggregated_df_filtered = aggregated_df_splitted[condition]\n",
    "            \n",
    "            # Generate a label for the plot\n",
    "            label = \" - \".join([f\"{col}={value}\" for col, value in zip(split_by, combination)])\n",
    "            title_label = title if title else metric\n",
    "            full_title = f\"{title_label} - {label}\" if show_split_by else title_label\n",
    "            \n",
    "            plot_metric_boxplot(aggregated_df_filtered, metric, full_title, y_label, value_to_show)\n",
    "            \n",
    "            if plot_violin:\n",
    "                plot_metric_violinplot(aggregated_df_filtered, metric, full_title, y_label, value_to_show)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print heatmap metrics\n",
    "def print_metrics_heatmap(metric_names, split_by, to_skip, title=None, y_label=None, value_to_show=\"value\", show_numbers=False, show_split_by=True):\n",
    "    # Filter DataFrame\n",
    "    df_filtered_by_name = df[df['name'].isin(metric_names)]\n",
    "\n",
    "    # Ensure split_by is a list\n",
    "    if isinstance(split_by, str):\n",
    "        split_by = [split_by]\n",
    "\n",
    "    # Add the 'name' column to split_by for grouping\n",
    "    group_by_columns = ['name'] + split_by + ['condition', 'workload']\n",
    "\n",
    "    if value_to_show != \"value\":\n",
    "        aggregated_df_splitted = df_filtered_by_name.groupby(group_by_columns).agg(\n",
    "            mean_value=('value', 'mean'),\n",
    "            sum_value=('value', 'sum')\n",
    "        ).reset_index().sort_values(\"condition\")\n",
    "        \n",
    "    else:\n",
    "        aggregated_df_splitted = df_filtered_by_name.groupby(group_by_columns + ['value']).agg(\n",
    "            mean_value=('value', 'mean'),\n",
    "        ).reset_index().sort_values(\"condition\")\n",
    "\n",
    "    # Filter out entries to be skipped\n",
    "    for metric in metric_names:\n",
    "        # Generate a unique combination of split_by values\n",
    "        for combination in aggregated_df_splitted[split_by].drop_duplicates().itertuples(index=False):\n",
    "            # Skip if any of the split_by values in the combination should be skipped\n",
    "            if any(el in to_skip for el in combination):\n",
    "                continue\n",
    "            \n",
    "            # Filter the DataFrame for the current combination\n",
    "            condition = (aggregated_df_splitted[split_by[0]] == combination[0])\n",
    "            \n",
    "            for i, col in enumerate(split_by[1:], start=1):\n",
    "                condition &= (aggregated_df_splitted[col] == combination[i])\n",
    "                \n",
    "            aggregated_df_filtered = aggregated_df_splitted[condition]\n",
    "            \n",
    "            # Generate a label for the plot\n",
    "            label = \" - \".join([f\"{col}={value}\" for col, value in zip(split_by, combination)])\n",
    "            title_label = title if title else metric\n",
    "            full_title = f\"{title_label} - {label}\" if show_split_by else title_label\n",
    "            plot_metric_heatmap(aggregated_df_filtered, metric, full_title, y_label, value_to_show, show_numbers=show_numbers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Boxplots</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Kube_endpoint</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = ['kube_endpoint_address_available', 'kube_endpoint_address_not_ready']\n",
    "metric_names = ['kube_endpoint_address_available']\n",
    "split_by='endpoint'\n",
    "\n",
    "wrong_endpoints = [\"kbench-service-oid-0-tid-0\", \"kcench-service-oid-0-tid-0\", \"jbench-service-oid-0-tid-0\", \"nnde-exporter\"]\n",
    "endpoints_to_skip = [\"prometheus-service\", \"kubernetes\", \"kube-state-metrics\"] + wrong_endpoints\n",
    "\n",
    "print_metrics(metric_names, split_by, endpoints_to_skip, y_label=\"Count\")\n",
    "# print_metrics_heatmap(metric_names, split_by, endpoints_to_skip, y_label=\"Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean endpoints vars\n",
    "del wrong_endpoints\n",
    "del endpoints_to_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Replica sets</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names = ['kube_replicaset_status_ready_replicas', 'kube_replicaset_status_replicas',]\n",
    "\n",
    "split_by = 'replicaset'\n",
    "\n",
    "wrong_rs = [\"kbench\", \"kcench\", \"jbench\", \"nnde-exporter\"]\n",
    "rs_to_skip = [\"prometheus-service\", \"kubernetes\", \"kube-state-metrics\"] + wrong_rs\n",
    "\n",
    "print_metrics(metric_names, split_by, rs_to_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean replcia set vars\n",
    "del wrong_rs\n",
    "del rs_to_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Node file system bytes</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = ['min node_filesystem_avail_bytes', 'min node_filesystem_free_bytes',]\n",
    "metric_names = ['min node_filesystem_free_bytes',]\n",
    "split_by = 'device'\n",
    "device_to_skip = [\"tmpfs\", \"shm\",] \n",
    "\n",
    "print_metrics(metric_names, split_by, device_to_skip, plot_violin=False, title=\"min node filesystem free space\", y_label=\"bytes\")\n",
    "# print_metrics_heatmap(metric_names, split_by, device_to_skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean node file system bytes\n",
    "del device_to_skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>node_filefd_allocated</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names = ['node_filefd_allocated',]\n",
    "\n",
    "split_by = 'instance'\n",
    "\n",
    "print_metrics(metric_names, split_by, [])\n",
    "# print_metrics_heatmap(metric_names, split_by, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>node_load5<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names = ['node_load5',]\n",
    "\n",
    "split_by = 'instance'\n",
    "\n",
    "print_metrics(metric_names, split_by, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Node memory</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"node_memory_Buffers_bytes\", \"node_memory_Cached_bytes\", \"node_memory_MemFree_bytes\", \"node_memory_Shmem_bytes\", \"node_memory_Slab_bytes\", \"node_memory_VmallocUsed_bytes\"]\n",
    "metric_names = [\"node_memory_MemFree_bytes\"]\n",
    "\n",
    "split_by = 'instance'\n",
    "to_skip = [\"192.168.100.2:9100\", \"192.168.100.3:9100\", \"192.168.100.4:9100\"]\n",
    "\n",
    "print_metrics(metric_names, split_by, to_skip, title=\"Free node memory - master node\", y_label=\"bytes\", show_split_by=False)\n",
    "# print_metrics_heatmap(metric_names, split_by, to_skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Node network stats</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"node_netstat_Tcp_CurrEstab\", \"node_procs_blocked\", \"node_sockstat_TCP_inuse\", \"node_sockstat_TCP_mem\",]\n",
    "metric_names = [\"node_netstat_Tcp_CurrEstab\"]\n",
    "\n",
    "split_by = 'instance'\n",
    "to_skip = [\"192.168.100.2:9100\", \"192.168.100.3:9100\", \"192.168.100.4:9100\"]\n",
    "\n",
    "print_metrics(metric_names, split_by, to_skip, title=\"node tcp connection estabilished - master node\", y_label=\"count\", show_split_by=False)\n",
    "# print_metrics(metric_names, split_by, [], value_to_show=\"sum_value\")\n",
    "# print_metrics_heatmap(metric_names, split_by, [], value_to_show=\"mean_value\", show_numbers=True)\n",
    "# print_metrics_heatmap(metric_names, split_by, [], title=\"TCP sockets in memory\", y_label=\"max count\", show_numbers=True, show_split_by=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Rates</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"rate node_context_switches_total\", \"rate process_cpu_seconds_total\", \"rate process_resident_memory_bytes\"]\n",
    "metric_names = [\"rate node_context_switches_total\"]\n",
    "\n",
    "split_by = 'instance'\n",
    "\n",
    "print_metrics(metric_names, split_by, [], title=\"node context switches total - master node\", y_label=\"rate\", show_split_by=False)\n",
    "# print_metrics_heatmap(metric_names, split_by, [], value_to_show=\"mean_value\", show_numbers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Node status capacity</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names = [\"sum kube_node_status_capacity_offset_offset_time)_by_ resource)\"]\n",
    "\n",
    "split_by = 'resource'\n",
    "to_skip = [\"cpu\", \"hugepages_2Mi\", \"pods\", \"ephemeral_storage\"]\n",
    "\n",
    "print_metrics(metric_names, split_by, to_skip, title=\"node status capacity offset\", y_label=\"sum of bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Rate node network stats</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"sum rate node_netstat_Tcp_InErrs\", \"sum rate node_netstat_Tcp_RetransSegs\", \"sum rate node_network_carrier_changes_total\", \"sum rate node_network_receive_packets_total\", \"sum rate node_network_transmit_packets_total\"]\n",
    "metric_names = [\"sum rate node_netstat_Tcp_RetransSegs\"]\n",
    "\n",
    "split_by = 'instance'\n",
    "to_skip = [\"192.168.100.2:9100\", \"192.168.100.3:9100\", \"192.168.100.4:9100\"]\n",
    "\n",
    "# print_metrics(metric_names, split_by, to_skip, title=\"packets rentransmitted\", y_label=\"sum of rate\")\n",
    "print_metrics_heatmap(metric_names, split_by, to_skip, title=\"packets rentransmitted\", y_label=\"sum of rate\", show_numbers=True, show_split_by=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Node work queue</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"sum rate workqueue_adds_total\", \"sum rate workqueue_depth\"]\n",
    "metric_names = [\"sum rate workqueue_depth\"]\n",
    "\n",
    "split_by = 'job'\n",
    "\n",
    "# Filter DataFrame\n",
    "df_filtered_by_name = df[df['name'].isin(metric_names)]\n",
    "\n",
    "aggregated_df_splitted = df_filtered_by_name.groupby(['name', 'condition', 'workload', 'value']).agg(\n",
    "    mean_value=('value', 'mean')\n",
    ").reset_index().sort_values(\"condition\")\n",
    "\n",
    "for metric in metric_names:\n",
    "    plot_metric_boxplot(aggregated_df_splitted, metric, f\"tasks added to workqueue\", y_label=\"sum of rate\")\n",
    "    plot_metric_heatmap(aggregated_df_splitted, metric, f\"workqueue depth\", y_label=\"sum of rate\", show_numbers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Status code</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"sum rate apiserver_request_total\", \"sum rate rest_client_requests_total\"]\n",
    "metric_names = [\"sum rate rest_client_requests_total\"]\n",
    "\n",
    "split_by = 'status_code'\n",
    "\n",
    "print_metrics(metric_names, split_by, [], title=\"rest client total requests\", y_label=\"sum of rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Changes</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"changes kube_pod_container_status_restarts_total[10s]_offset_offset_time)___0\", \"changes kube_pod_status_phase[10s]_offset_offset_time)_!=_0\"]\n",
    "metric_names = [\"changes kube_pod_status_phase[10s]_offset_offset_time)_!=_0\"]\n",
    "\n",
    "# split_by = 'container'\n",
    "# to_skip = [\"iello-dep\", \"hdllo-dep\", \"kube-proxy\"]\n",
    "# print_metrics(metric_names, split_by, to_skip, value_to_show=\"sum_value\")\n",
    "# print_metrics_heatmap(metric_names, split_by, to_skip, value_to_show=\"sum_value\", title=\"container restarts total\", y_label=\"sum\", show_numbers=True)\n",
    "\n",
    "split_by = 'job'\n",
    "to_skip = [\"Succeeded\"]\n",
    "# print_metrics(metric_names, split_by, to_skip, y_label=\"Sum\", value_to_show=\"sum_value\")\n",
    "print_metrics_heatmap(metric_names, split_by, [], value_to_show=\"sum_value\", title=\"pods status phase changes\", y_label=\"sum\", show_numbers=True, show_split_by=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Reason</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define desired metric names\n",
    "metric_names_full = [\"kube_pod_container_status_terminated_reason\", \"kube_pod_container_status_waiting_reason\"]\n",
    "metric_names = [\"kube_pod_container_status_terminated_reason\"]\n",
    "\n",
    "split_by = [\"reason\"]\n",
    "to_skip = [\"iello-dep\", \"hdllo-dep\", \"kube-proxy\", \"completed\", \"kube-flannel\", \"ContainerStatusUnknown\"]\n",
    "\n",
    "# print_metrics(metric_names, split_by, to_skip, y_label=\"Sum\", value_to_show=\"sum_value\")\n",
    "print_metrics_heatmap(metric_names, split_by, to_skip, title=\"container terminated reason\", y_label=\"sum\", value_to_show=\"sum_value\", show_numbers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Histograms</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "metric_names_full = [\"sum rate apiserver_request_duration_seconds_bucket\", \"sum rate rest_client_request_duration_seconds_bucket[10s]_offset_offset_time))_by_ le)\", \"sum rate workqueue_queue_duration_seconds_bucket\"]\n",
    "metric_names = [\"sum rate rest_client_request_duration_seconds_bucket[10s]_offset_offset_time))_by_ le)\"]\n",
    "\n",
    "df_filtered_by_name = df[df['name'].isin(metric_names)]\n",
    "df_grouped = df_filtered_by_name.groupby(['name', 'le', 'condition', 'workload']).agg(\n",
    "        mean_value=('value', 'mean')\n",
    ").reset_index().sort_values(\"le\").sort_values(\"condition\")\n",
    "\n",
    "sns.set_theme(context=\"notebook\", style=\"white\", font_scale=1.2, palette=\"tab10\")\n",
    "\n",
    "for metric_name in metric_names:\n",
    "\n",
    "        # Create subplots: 1 row and 3 columns (for the three workloads)\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "        # Iterate through each workload and corresponding subplot axis\n",
    "        for i, workload in enumerate([\"availab\", \"deploy\", \"scale\"]):\n",
    "                # Filter the DataFrame for the specific workload and create a copy\n",
    "                filtered_df = df_grouped[df_grouped['workload'] == workload].copy()\n",
    "                filtered_df = filtered_df[filtered_df['name'] == metric_name].copy()\n",
    "\n",
    "                # Replace +Inf with a large finite value using .loc[]\n",
    "                filtered_df.loc[filtered_df['le'] == float('inf'), 'le'] = 65\n",
    "\n",
    "                # Filter by le value if necessary\n",
    "                # filtered_df = filtered_df[filtered_df['le'] < 61]\n",
    "\n",
    "                # Plotting the occurrence (frequency) histogram for all conditions in the same subplot\n",
    "                ax = sns.histplot(x='le', y='mean_value', data=filtered_df, bins=70, hue='condition', palette=\"husl\", ax=axes[i])\n",
    "                axes[i].set_title(f'workload: {workload}')\n",
    "                axes[i].set_xlabel('')\n",
    "                axes[i].set_ylabel(' ')\n",
    "                \n",
    "                ticks = np.concatenate((np.arange(0, 10, step=2), np.arange(10, 61, step=10)))\n",
    "                # Add the last tick with 'infinite' label\n",
    "                ticks = np.append(ticks, 65)\n",
    "                tick_labels = np.append(ticks[:-1], 'inf')\n",
    "                \n",
    "                ''' workqueue\n",
    "                # Replace +Inf with a large finite value using .loc[]\n",
    "                filtered_df.loc[filtered_df['le'] == float('inf'), 'le'] = 11\n",
    "\n",
    "                # Filter by le value if necessary\n",
    "                # filtered_df = filtered_df[filtered_df['le'] < 61]\n",
    "\n",
    "                # Plotting the occurrence (frequency) histogram for all conditions in the same subplot\n",
    "                ax = sns.histplot(x='le', y='mean_value', data=filtered_df, bins=60, hue='condition', palette=\"husl\", ax=axes[i])\n",
    "                axes[i].set_title(f'workload: {workload}')\n",
    "                axes[i].set_xlabel('')\n",
    "                axes[i].set_ylabel(' ')\n",
    "                \n",
    "                ticks = (np.arange(0, 11, step=2))\n",
    "                # Add the last tick with 'infinite' label\n",
    "                ticks = np.append(ticks, 11)\n",
    "                tick_labels = np.append(ticks[:-1], 'inf')\n",
    "                \n",
    "                '''\n",
    "                \n",
    "                ax.set_xticks(ticks)\n",
    "                ax.set_xticklabels(tick_labels)\n",
    "\n",
    "                sns.move_legend(ax, \"lower right\")\n",
    "\n",
    "        # Set the shared y-label\n",
    "        fig.supylabel('requests per seconds rate')\n",
    "        fig.supxlabel('le (request solved under x second)')\n",
    "        fig.suptitle(\"rest client requests duration histogram\", fontsize=16)\n",
    "        fig.set_label(\" \")\n",
    "        # Adjust the layout for better spacing\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear histogram's vars\n",
    "del ticks\n",
    "del ax\n",
    "del fig\n",
    "del axes\n",
    "del df_grouped\n",
    "del df_filtered_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metrics and conditions to plot\n",
    "metric_names_full = [\n",
    "    \"sum rate apiserver_request_duration_seconds_bucket\", \n",
    "    \"sum rate rest_client_request_duration_seconds_bucket[10s]_offset_offset_time))_by_ le)\", \n",
    "    \"sum rate workqueue_queue_duration_seconds_bucket\"\n",
    "]\n",
    "\n",
    "metric_names = [\"sum rate rest_client_request_duration_seconds_bucket[10s]_offset_offset_time))_by_ le)\"]\n",
    "\n",
    "df_filtered_by_name = df[df['name'].isin(metric_names)]\n",
    "df_grouped = df_filtered_by_name.groupby(['name', 'le', 'condition', 'workload']).agg(\n",
    "    mean_value=('value', 'mean')\n",
    ").reset_index().sort_values(\"le\").sort_values(\"condition\")\n",
    "\n",
    "for metric_name in metric_names:\n",
    "\n",
    "    # Create subplots: 4 rows (for each condition) and 3 columns (for each workload)\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(18, 24), sharey=True)\n",
    "    \n",
    "    # Define conditions and workloads\n",
    "    conditions = df_grouped['condition'].unique()\n",
    "    workloads = [\"availab\", \"deploy\", \"scale\"]\n",
    "    \n",
    "    # Iterate through each condition\n",
    "    for row_idx, condition in enumerate(conditions):\n",
    "        \n",
    "        # Iterate through each workload and corresponding subplot axis\n",
    "        for col_idx, workload in enumerate(workloads):\n",
    "            \n",
    "            # Filter the DataFrame for the specific workload and condition\n",
    "            filtered_df = df_grouped[(df_grouped['workload'] == workload) & (df_grouped['condition'] == condition)].copy()\n",
    "            filtered_df = filtered_df[filtered_df['name'] == metric_name]\n",
    "            \n",
    "            # Replace +Inf with a large finite value using .loc[]\n",
    "            filtered_df.loc[filtered_df['le'] == float('inf'), 'le'] = 65\n",
    "            \n",
    "            # Plotting the histogram for each condition and workload\n",
    "            ax = sns.histplot(\n",
    "                x='le', \n",
    "                y='mean_value', \n",
    "                data=filtered_df, \n",
    "                bins=15, \n",
    "                palette=\"husl\", \n",
    "                hue=\"le\",\n",
    "                ax=axes[row_idx, col_idx],\n",
    "                legend=False\n",
    "            )\n",
    "            \n",
    "            # Set title and labels\n",
    "            axes[row_idx, col_idx].set_title(f'Workload: {workload} - Condition: {condition}')\n",
    "            axes[row_idx, col_idx].set_xlabel('le (request solved under x second)')\n",
    "            axes[row_idx, col_idx].set_ylabel('requests per seconds rate' if col_idx == 0 else '')\n",
    "            \n",
    "            # Define ticks for le axis\n",
    "            # ticks = np.concatenate((np.arange(0, 10, step=2), np.arange(10, 61, step=10)))\n",
    "            # ticks = np.append(ticks, 65)\n",
    "            # tick_labels = np.append(ticks[:-1], 'inf')\n",
    "            \n",
    "            # Set xticks and labels\n",
    "            ax.set_xticks(ticks)\n",
    "            ax.set_xticklabels(tick_labels)\n",
    "            \n",
    "            \n",
    "    \n",
    "    # Set the overall figure title\n",
    "    fig.suptitle(f\"{metric_name} Duration Histogram\", fontsize=16)\n",
    "    \n",
    "    # Adjust the layout for better spacing\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Times</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the time from when a\n",
    "def print_time_metrics(metric_names_to_differ):\n",
    "    # Filter DataFrame by metric names\n",
    "    df_filtered = df[df['name'].isin(metric_names_to_differ)]\n",
    "\n",
    "    # Define the necessary grouping columns\n",
    "    group_by_columns = ['name', 'condition', 'workload', 'uid']\n",
    "    group_by_columns2 = ['condition', 'workload', 'uid']\n",
    "\n",
    "    # Aggregate data\n",
    "    aggregated_df = df_filtered.groupby(group_by_columns).agg(\n",
    "        mean_value=('value', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    aggregated_df_splitted = aggregated_df.groupby(group_by_columns2).agg(\n",
    "        diff_value=('mean_value', lambda x: x.max() - x.min())\n",
    "    ).reset_index()\n",
    "\n",
    "    # Set up subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6), sharey=True)\n",
    "\n",
    "    # Plot each workload in separate subplots\n",
    "    for i, workload in enumerate([\"availab\", \"deploy\", \"scale\"]):\n",
    "        filtered_df = aggregated_df_splitted[aggregated_df_splitted['workload'] == workload]\n",
    "        \n",
    "        # Create a boxplot\n",
    "        sns.boxplot(x='condition', y='diff_value', data=filtered_df, hue='condition', ax=axes[i])\n",
    "        \n",
    "        axes[i].set_title(workload)\n",
    "        axes[i].set_xlabel('')\n",
    "        axes[i].set_ylabel(\"seconds\")\n",
    "\n",
    "    # Set shared labels and title\n",
    "    fig.supxlabel('Condition')\n",
    "    fig.suptitle(f\"pod created to containers started\", fontsize=16)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define desired metric names\n",
    "metric_names_full = [\"kube_pod_container_state_started\", \"kube_pod_status_scheduled_time\", \"kube_pod_created\", \"kube_pod_start_time\"]\n",
    "metric_names = [\"kube_pod_status_scheduled_time\", \"kube_pod_created\"]\n",
    "metric_names2 = [\"kube_pod_status_scheduled_time\", \"kube_pod_container_state_started\"]\n",
    "metric_names3 = [\"kube_pod_created\", \"kube_pod_container_state_started\"]\n",
    "\n",
    "print_time_metrics(metric_names)\n",
    "print_time_metrics(metric_names2)\n",
    "print_time_metrics(metric_names3)\n",
    "\n",
    "# Check if exists data with a time difference\n",
    "# inconsistent_data = df[(df['name'] == 'kube_pod_created') | (df['name'] == 'kube_pod_container_state_started')] \\\n",
    "#     .groupby('uid') \\\n",
    "#     .filter(lambda group: len(group['value'].unique()) > 1)\n",
    "\n",
    "# print(inconsistent_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Verifica rapporto alert corretti / false segnalazioni </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rapporto alert missing e falsi per node_memory_MemFree_bytes\n",
    "\n",
    "df_filtered_to_alert = df[df['name'].isin([\"node_memory_MemFree_bytes\"])]\n",
    "\n",
    "# Filter out rows where 'instance' is in to_skip before grouping\n",
    "to_skip = [\"192.168.100.2:9100\", \"192.168.100.3:9100\", \"192.168.100.4:9100\"] # worker nodes\n",
    "df_filtered_to_alert_clear = df_filtered_to_alert[~df_filtered_to_alert['instance'].isin(to_skip)]\n",
    "\n",
    "# group errors rows\n",
    "group_by_columns = ['name', 'instance', 'condition', 'workload']\n",
    "df_filtered_to_alert_clear_errors = df_filtered_to_alert_clear[~df_filtered_to_alert_clear['condition'].isin([\"Baselines\"])]\n",
    "\n",
    "aggregated_df_splitted_errors = df_filtered_to_alert_clear.groupby(group_by_columns + ['value']).agg(\n",
    "    mean_value=('value', 'mean'),\n",
    ").reset_index().sort_values(\"condition\")\n",
    "\n",
    "# take baselines mean value\n",
    "group_by_columns_mean_values = ['name', 'instance', 'condition']\n",
    "aggregated_df_splitted_mean_values = df_filtered_to_alert_clear.groupby(group_by_columns_mean_values).agg(\n",
    "    mean_value=('value', 'mean'),\n",
    ").reset_index().sort_values(\"condition\")\n",
    "\n",
    "\n",
    "# Take the mean value of baselines and set the lower treshold as [mean value minus 15%]\n",
    "baseline_mean_values = aggregated_df_splitted_mean_values[aggregated_df_splitted_mean_values['condition'] == 'Baselines']['mean_value'][0]\n",
    "treshold = baseline_mean_values - ( baseline_mean_values * 0.15 )\n",
    "\n",
    "\n",
    "under_treshold_rows = aggregated_df_splitted_errors[aggregated_df_splitted_errors['value'] < treshold]\n",
    "\n",
    "under_treshold_rows_only_errors = under_treshold_rows[under_treshold_rows['condition'] != \"Baselines\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> ALL FIELDS </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(field_group)\n",
    "print_all = False\n",
    "\n",
    "if print_all:\n",
    "    for label, content in field_group.items():\n",
    "        for metric in content:\n",
    "            if not metric.isnumeric():\n",
    "            \n",
    "                print(f\"\\n{metric}\")\n",
    "                try:\n",
    "                    # plot_metric_violin(df, metric)\n",
    "                    plot_metric_boxplot(df, metric)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
